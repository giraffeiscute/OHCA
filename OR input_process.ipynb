{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import re\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import h3 \n",
    "import shap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_l7_df = pd.read_csv('h3_l7_df_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定plt環境\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index=[]\n",
    "test_index=[]\n",
    "for i in range(0,h3_l7_df.shape[0]):\n",
    "    geo_location = h3.h3_to_geo(h3_l7_df.iloc[i]['id'])\n",
    "\n",
    "    if (geo_location[1]) > (-76.05): #把經度大於-76.05的 當train (東邊是train)\n",
    "        train_index.append(i)\n",
    "    else:\n",
    "        test_index.append(i)\n",
    "\n",
    "# 分割訓練集和測試集\n",
    "train_h3_l7_df = h3_l7_df.iloc[train_index]\n",
    "test_h3_l7_df = h3_l7_df.iloc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "# 將 h3_l7_df 資料框中的 'id' 列移除，僅保留數據進行正規化\n",
    "h3_spatial_data = h3_l7_df.drop('id', axis=1)\n",
    "\n",
    "\n",
    "# # # 對數據進行正規化：將每個數據列的最小值調整為 0，最大值調整為 1\n",
    "normalized_spatial_data = (h3_spatial_data - h3_spatial_data.min()) / (h3_spatial_data.max() - h3_spatial_data.min())\n",
    "\n",
    "#設定OHCA正規化反函數 方便把預測結果返回原本scale\n",
    "ohca_reguli_inverse = (h3_l7_df.ohca.max()-h3_l7_df.ohca.min()) + h3_l7_df.ohca.min()\n",
    "\n",
    "# 將 DataFrame 轉換為 numpy array，並設定數據類型為 np.float64\n",
    "spatial_data = np.array(normalized_spatial_data).astype(np.float64)\n",
    "\n",
    "\n",
    "train_spatial_data = spatial_data[train_index]\n",
    "test_spatial_data = spatial_data[test_index]\n",
    "\n",
    "print(len(train_index))\n",
    "print(len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    \"\"\"\n",
    "    用於迴歸任務的神經網絡模型 Regressor。\n",
    "    \n",
    "    結構:\n",
    "    - 兩層隱藏層，並使用 ReLU 激活函數\n",
    "    - 最後一層為線性層，不使用激活函數（適用於迴歸）\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=2, hidden_size=32, output_size=1):\n",
    "        super().__init__()\n",
    "        # 定義三層全連接層\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)     # 第一層：輸入層到隱藏層\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)    # 第二層：隱藏層到隱藏層\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)    # 第三層：隱藏層到輸出層\n",
    "\n",
    "        # 初始化權重和偏置\n",
    "        nn.init.normal_(self.fc1.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc1.bias, 0)\n",
    "        nn.init.normal_(self.fc2.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc2.bias, 0)\n",
    "        nn.init.normal_(self.fc3.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc3.bias, 0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # 前向傳播過程\n",
    "        output = F.relu(self.fc1(input))  # 第一層 + ReLU 激活\n",
    "        output = F.relu(self.fc2(output)) # 第二層 + ReLU 激活\n",
    "        output = self.fc3(output)         # 第三層（不使用激活函數）\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [01:03<00:00, 469.84it/s]\n"
     ]
    }
   ],
   "source": [
    "window_size = 1\n",
    "seed = 7890 #7890\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def train_reg(spatial_data, \n",
    "              s_net,\n",
    "              s_net_optim, \n",
    "              window_size, iter_num=5000):\n",
    "    \"\"\"\n",
    "    訓練 s_net  網絡來預測 spatial_data 中的數據。\n",
    "    \n",
    "    參數:\n",
    "    - spatial_data: numpy array，包含訓練數據\n",
    "    - s_net: 神經網絡模型\n",
    "    - s_net_optim: 優化器\n",
    "    - window_size: 每次迭代的隨機取樣大小\n",
    "    - iter_num: 訓練迭代次數\n",
    "    \n",
    "    返回:\n",
    "    - loss_array: 每次迭代的損失值\n",
    "    - t_fea_array, s_fea_array: 用於存儲特徵的暫時性陣列（目前未使用）\n",
    "    \"\"\"\n",
    "\n",
    "    loss_array = []     # 儲存每次迭代的損失\n",
    "    t_fea_array = []    # 預留用於儲存暫時性特徵的空列表\n",
    "    s_fea_array = []    # 預留用於儲存暫時性特徵的空列表\n",
    "\n",
    "    for _ in tqdm(range(iter_num)):\n",
    "        \n",
    "        # 隨機選擇一組數據索引\n",
    "        h3_l7_id = np.random.choice(spatial_data.shape[0] - 1, window_size)\n",
    "\n",
    "\n",
    "        # 提取目標變數（即輸入的最後一列數據）並轉為 Tensor\n",
    "        ohca = spatial_data[h3_l7_id, -1].reshape(-1, 1)\n",
    "        ohca = torch.autograd.Variable(torch.FloatTensor(ohca))\n",
    "\n",
    "        # p_pred 用於預測目標變數\n",
    "        p_pred = s_net(torch.autograd.Variable(torch.FloatTensor(spatial_data[h3_l7_id, :-1]))).reshape(-1, 1)\n",
    "\n",
    "        # 定義均方誤差損失\n",
    "        mseloss = torch.nn.MSELoss(reduction='sum')\n",
    "        loss = mseloss(p_pred, ohca)\n",
    "        \n",
    "        # 清空前一次計算的梯度\n",
    "        s_net_optim.zero_grad()\n",
    "        \n",
    "        \n",
    "        # 計算損失的梯度\n",
    "        autograd.backward(loss)\n",
    "\n",
    "        # 更新神經網絡參數\n",
    "        s_net_optim.step()\n",
    "        \n",
    "        # 儲存損失值\n",
    "        loss_array.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    return loss_array, t_fea_array, s_fea_array\n",
    "\n",
    "# 初始化模型和優化器\n",
    "s_net = Regressor(input_size=spatial_data.shape[1] - 1, hidden_size=spatial_data.shape[1] * 2, output_size=1)\n",
    "s_net_optim = optim.Adam(s_net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "iter_num=30000\n",
    "# 執行訓練過程\n",
    "loss_array, t_fea_array, s_fea_array = train_reg(train_spatial_data, s_net,\n",
    "                                                 s_net_optim,\n",
    "                                                 window_size, iter_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_head_train = s_net(torch.autograd.Variable(torch.FloatTensor(train_spatial_data[:, :-1]))).detach().numpy()*ohca_reguli_inverse\n",
    "y_train = train_spatial_data[:, -1]*ohca_reguli_inverse\n",
    "y_head_test = s_net(torch.autograd.Variable(torch.FloatTensor(test_spatial_data[:, :-1]))).detach().numpy()*ohca_reguli_inverse\n",
    "y_test = test_spatial_data[:, -1].reshape(-1, 1)*ohca_reguli_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sum = np.sum(y_test)\n",
    "total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of test set=  6.406070350332463\n",
      "R² of test set=  0.6517364254708865\n",
      "ADJ R² of test set=  2.408196192661198\n"
     ]
    }
   ],
   "source": [
    "mae = np.abs(y_head_test-y_test)\n",
    "ans_mae = mae.sum()/mae.shape[0]\n",
    "\n",
    "print('MAE of test set= ',ans_mae)\n",
    "\n",
    "# 計算殘差變異\n",
    "ss_residual = np.sum((y_test - y_head_test) ** 2)\n",
    "\n",
    "# 計算總變異量\n",
    "ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "\n",
    "# 計算 R²\n",
    "r_squared = 1 - (ss_residual / ss_total)\n",
    "\n",
    "n = mae.shape[0]          # Number of data points\n",
    "p = train_spatial_data.shape[1]            # Number of predictors\n",
    "\n",
    "# Adjusted R-squared calculation\n",
    "r_squared_adj = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(\"R² of test set= \", r_squared)\n",
    "print(\"ADJ R² of test set= \", r_squared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設 `spatial_data` 包含背景數據，用於 SHAP 的解釋\n",
    "background_data = torch.FloatTensor(train_spatial_data[:, :-1])  \n",
    "test_data = torch.FloatTensor(test_spatial_data[:, :-1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 建立 SHAP 解釋器，使用背景數據\u001b[39;00m\n\u001b[0;32m      2\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mGradientExplainer(s_net, background_data)\n\u001b[1;32m----> 3\u001b[0m shap_values_test \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(test_data)\u001b[38;5;241m*\u001b[39mohca_reguli_inverse\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get the shap values from my test data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m test_features_df \u001b[38;5;241m=\u001b[39m h3_spatial_data\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_gradient.py:164\u001b[0m, in \u001b[0;36mGradientExplainer.shap_values\u001b[1;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, nsamples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, rseed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_variances\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the values for the model applied to X.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mshap_values(X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\n",
      "File \u001b[1;32mc:\\Users\\Yuan\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_gradient.py:580\u001b[0m, in \u001b[0;36m_PyTorchGradient.shap_values\u001b[1;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[0;32m    577\u001b[0m     x \u001b[38;5;241m=\u001b[39m X[a][j]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(X[a][j]\u001b[38;5;241m.\u001b[39mshape, device\u001b[38;5;241m=\u001b[39mX[a]\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mnormal_() \\\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_smoothing\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 580\u001b[0m     x \u001b[38;5;241m=\u001b[39m X[a][j]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m    581\u001b[0m samples_input[a][k] \u001b[38;5;241m=\u001b[39m (t \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m t) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_inputs[a][rind])\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39m\\\n\u001b[0;32m    582\u001b[0m     clone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 建立 SHAP 解釋器，使用背景數據\n",
    "explainer = shap.GradientExplainer(s_net, background_data)\n",
    "shap_values_test = explainer.shap_values(test_data)*ohca_reguli_inverse\n",
    "# Get the shap values from my test data\n",
    "\n",
    "test_features_df = h3_spatial_data.iloc[:, :-1]\n",
    "feature_names = test_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把SHAP 換成壞圖之格式\n",
    "shap_col = shap_values_test.shape[0]\n",
    "shap_row = shap_values_test.shape[1]\n",
    "shap_values_test_2D = shap_values_test.reshape(shap_col,shap_row)\n",
    "# shap.summary_plot(shap_values_test_2D, test_data,feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_w_SHAP = [f'shap {col}' for col in feature_names] # 在每個列名前加上 'shap'\n",
    "SHAP_df = pd.DataFrame(shap_values_test_2D, columns=feature_names_w_SHAP) #換成 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = test_h3_l7_df.reset_index(drop=True)\n",
    "df2 = SHAP_df.reset_index(drop=True)\n",
    "test_h3_l7_df_S = pd.concat([df1, df2], axis=1) #合併SHAP值到test_h3_l7_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化結果 DataFrame\n",
    "spatial_data_score = pd.DataFrame()\n",
    "spatial_data_score['id'] = test_h3_l7_df_S['id']\n",
    "\n",
    "# 初始化字典來存儲計算結果\n",
    "results_dict = {}\n",
    "# 逐列處理\n",
    "for col in feature_names:\n",
    "    col_result = []  # 存儲當前特徵的計算結果\n",
    "    \n",
    "    # 遍歷每一行\n",
    "    for row in range(test_h3_l7_df_S.shape[0]):\n",
    "        building_name = col\n",
    "        shap_name = 'shap ' + building_name\n",
    "        denominator = test_h3_l7_df_S.iloc[row][building_name] # 分母\n",
    "        numerator = test_h3_l7_df_S.iloc[row][shap_name]  # 分子\n",
    "        \n",
    "        # 處理分母為 0 的情況\n",
    "        if denominator == 0:\n",
    "            col_result.append(numerator)\n",
    "        else:\n",
    "            col_result.append(numerator / denominator)\n",
    "\n",
    "    # 將結果存入字典\n",
    "    results_dict[col] = col_result\n",
    "\n",
    "# 一次性加入所有計算結果\n",
    "spatial_data_score = pd.concat([spatial_data_score, pd.DataFrame(results_dict)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 初始化結果 DataFrame\n",
    "# spatial_data_score = pd.DataFrame()\n",
    "# spatial_data_score['id'] = test_h3_l7_df_S['id']\n",
    "\n",
    "# # 循環處理每一列\n",
    "# for col in range(feature_names.shape[0]):\n",
    "#     col_result = []  # 用於存儲當前列的計算結果\n",
    "    \n",
    "#     # 遍歷每一行\n",
    "#     for row in range(test_h3_l7_df_S.shape[0]):\n",
    "#         denominator = test_h3_l7_df_S.iloc[row, col + 1]  # 分母\n",
    "#         numerator = test_h3_l7_df_S.iloc[row, col + feature_names.shape[0] + 3]  # 分子\n",
    "        \n",
    "#         # 如果分母為 0，直接使用原分子數據\n",
    "#         if denominator == 0:\n",
    "#             col_result.append(numerator)\n",
    "#         else:\n",
    "#             col_result.append(numerator / denominator)  # 正常執行除法\n",
    "    \n",
    "#     # 將當前列結果存入結果 DataFrame\n",
    "#     spatial_data_score[feature_names[col]] = col_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 製造有SHAP值的poi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df = pd.read_csv('poi_df.csv') #讀進原檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_values = spatial_data_score['id']\n",
    "test_poi_df = poi_df[poi_df['h3_l7'].isin(selected_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>h3_l7</th>\n",
       "      <th>building</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356567877</td>\n",
       "      <td>36.709595</td>\n",
       "      <td>-76.047987</td>\n",
       "      <td>872af626dffffff</td>\n",
       "      <td>place_of_worship</td>\n",
       "      <td>0.086722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356567948</td>\n",
       "      <td>36.586005</td>\n",
       "      <td>-76.082863</td>\n",
       "      <td>872af051cffffff</td>\n",
       "      <td>place_of_worship</td>\n",
       "      <td>0.373893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356568033</td>\n",
       "      <td>36.733205</td>\n",
       "      <td>-76.097433</td>\n",
       "      <td>872af626effffff</td>\n",
       "      <td>place_of_worship</td>\n",
       "      <td>0.357984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356568069</td>\n",
       "      <td>36.557653</td>\n",
       "      <td>-76.073542</td>\n",
       "      <td>872af0519ffffff</td>\n",
       "      <td>place_of_worship</td>\n",
       "      <td>0.110818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356568361</td>\n",
       "      <td>36.850422</td>\n",
       "      <td>-76.160777</td>\n",
       "      <td>872af6353ffffff</td>\n",
       "      <td>place_of_worship</td>\n",
       "      <td>-0.167937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99719</th>\n",
       "      <td>7485109</td>\n",
       "      <td>36.866139</td>\n",
       "      <td>-76.133943</td>\n",
       "      <td>872af6350ffffff</td>\n",
       "      <td>residential</td>\n",
       "      <td>-0.0187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99720</th>\n",
       "      <td>9637418</td>\n",
       "      <td>36.858806</td>\n",
       "      <td>-76.170325</td>\n",
       "      <td>872af622cffffff</td>\n",
       "      <td>house</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99721</th>\n",
       "      <td>11674759</td>\n",
       "      <td>36.819752</td>\n",
       "      <td>-76.076312</td>\n",
       "      <td>872af634effffff</td>\n",
       "      <td>school</td>\n",
       "      <td>0.595646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99722</th>\n",
       "      <td>12032839</td>\n",
       "      <td>36.790276</td>\n",
       "      <td>-76.111886</td>\n",
       "      <td>872af6266ffffff</td>\n",
       "      <td>residential</td>\n",
       "      <td>-0.009574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99723</th>\n",
       "      <td>12199937</td>\n",
       "      <td>36.824307</td>\n",
       "      <td>-76.079470</td>\n",
       "      <td>872af634effffff</td>\n",
       "      <td>commercial</td>\n",
       "      <td>0.048088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99724 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           osmid        lat        lon            h3_l7          building  \\\n",
       "0      356567877  36.709595 -76.047987  872af626dffffff  place_of_worship   \n",
       "1      356567948  36.586005 -76.082863  872af051cffffff  place_of_worship   \n",
       "2      356568033  36.733205 -76.097433  872af626effffff  place_of_worship   \n",
       "3      356568069  36.557653 -76.073542  872af0519ffffff  place_of_worship   \n",
       "4      356568361  36.850422 -76.160777  872af6353ffffff  place_of_worship   \n",
       "...          ...        ...        ...              ...               ...   \n",
       "99719    7485109  36.866139 -76.133943  872af6350ffffff       residential   \n",
       "99720    9637418  36.858806 -76.170325  872af622cffffff             house   \n",
       "99721   11674759  36.819752 -76.076312  872af634effffff            school   \n",
       "99722   12032839  36.790276 -76.111886  872af6266ffffff       residential   \n",
       "99723   12199937  36.824307 -76.079470  872af634effffff        commercial   \n",
       "\n",
       "          score  \n",
       "0      0.086722  \n",
       "1      0.373893  \n",
       "2      0.357984  \n",
       "3      0.110818  \n",
       "4     -0.167937  \n",
       "...         ...  \n",
       "99719   -0.0187  \n",
       "99720  0.001472  \n",
       "99721  0.595646  \n",
       "99722 -0.009574  \n",
       "99723  0.048088  \n",
       "\n",
       "[99724 rows x 6 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_poi_df = test_poi_df.reset_index(drop=True)\n",
    "test_poi_df['score'] = None  # 初始化 'score' 列為空值\n",
    "\n",
    "# 循環處理每一行\n",
    "for i in range(0, test_poi_df.shape[0]):\n",
    "    poi_id = test_poi_df['h3_l7'].iloc[i]  # 取得當前行的 poi_id\n",
    "    building_type = test_poi_df['building'].iloc[i]  # 取得當前行的 building_type\n",
    "    \n",
    "    # 查找 spatial_data_score 中對應的 id 和 amenity\n",
    "    positions = spatial_data_score.index[spatial_data_score['id'] == poi_id]\n",
    " \n",
    "        # 檢查 building_type 是否在 spatial_data_score 的列中\n",
    "    if building_type in spatial_data_score.columns:\n",
    "        building_score = spatial_data_score.loc[positions, building_type]\n",
    "        \n",
    "        if not building_score.empty:\n",
    "            # 如果找到了對應的建築分數，將其轉換為數字並儲存\n",
    "            test_poi_df.loc[i, 'score'] = pd.to_numeric(building_score.iloc[0])\n",
    "        else:\n",
    "            # 如果沒有找到對應的 building_type，可以設為 NaN 或其他預設值\n",
    "            test_poi_df.loc[i, 'score'] = None\n",
    "    else:\n",
    "        # 如果 building_type 不存在於 spatial_data_score，設為 NaN 或其他預設值\n",
    "        test_poi_df.loc[i, 'score'] = None\n",
    "\n",
    "\n",
    "# 檢查結果\n",
    "test_poi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.086722\n",
       "1        0.373893\n",
       "2        0.357984\n",
       "3        0.110818\n",
       "4       -0.167937\n",
       "           ...   \n",
       "99719     -0.0187\n",
       "99720    0.001472\n",
       "99721    0.595646\n",
       "99722   -0.009574\n",
       "99723    0.048088\n",
       "Name: score, Length: 99724, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_poi_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803.4365794421532"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list(test_poi_df['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_poi_df.to_csv('test_poi_df.csv', index=False, sep=',', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_area(r1, r2, d):\n",
    "    if d >= r1 + r2:\n",
    "        return 0  # 兩圓不相交\n",
    "    elif d <= abs(r1 - r2):\n",
    "        return np.pi * min(r1, r2)**2  # 一圓包含另一圓\n",
    "    else:\n",
    "        # 使用公式計算相交面積\n",
    "        term1 = r1**2 * np.arccos((d**2 + r1**2 - r2**2) / (2 * d * r1))\n",
    "        term2 = r2**2 * np.arccos((d**2 + r2**2 - r1**2) / (2 * d * r2))\n",
    "        term3 = 0.5 * np.sqrt((-d + r1 + r2) * (d + r1 - r2) * (d - r1 + r2) * (d + r1 + r2))\n",
    "        return term1 + term2 - term3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#緯度（latitude） 經度（longitude）\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # 將經緯度轉換為弧度\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # 計算差異\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    # 哈弗辛公式\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    \n",
    "    # 地球半徑（公里）\n",
    "    R = 6371.0\n",
    "    \n",
    "    # 計算距離\n",
    "    distance = R * c #單位為km\n",
    "    return distance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.839208192292585"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = test_poi_df[test_poi_df['h3_l7'] == '872af6353ffffff']\n",
    "sum(a.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_score(AED_location, AED_range):\n",
    "    score_list = []\n",
    "    center_radius = 1.21  # 根據 H3 Level 7 的網格大小進行調整\n",
    "    for i in range(0, test_poi_df.shape[0]):\n",
    "        distance = haversine(AED_location[0], AED_location[1], test_poi_df.iloc[i]['lat'], test_poi_df.iloc[i]['lon'])\n",
    "        \n",
    "        # 如果 POI 在 AED 範圍外，跳過該 POI\n",
    "        if distance > AED_range or test_poi_df.iloc[i]['score'] ==None:\n",
    "            continue\n",
    "        else:\n",
    "            # 將 H3 網格編碼轉換為經緯度\n",
    "            L7_center = h3.h3_to_geo(test_poi_df.iloc[i]['h3_l7'])\n",
    "            center_distance = haversine(AED_location[0], AED_location[1], L7_center[0], L7_center[1])\n",
    "            \n",
    "            # 計算重疊面積的比例\n",
    "            intersection_area_value = intersection_area(AED_range, center_radius, center_distance)\n",
    "            proportion = intersection_area_value / ((center_radius ** 2) * np.pi)\n",
    "            # 根據比例計算加權分數\n",
    "            Score = test_poi_df.iloc[i]['score'] * proportion\n",
    "            score_list.append(Score)\n",
    "    \n",
    "    return sum(score_list)  # 返回分數列表，方便後續處理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.346658917662801"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_score(h3.h3_to_geo('872af6309ffffff'),0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36.90609575498717, -76.14199701723689)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3.h3_to_geo('872af6309ffffff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohca_df = pd.read_csv('OHCAs.csv')\n",
    "# h3_l7 = []\n",
    "\n",
    "# for i in range(ohca_df.shape[0]):\n",
    "#     h3_l7.append(h3.geo_to_h3(ohca_df.Latitude[i], ohca_df.Longitude[i], resolution=7))\n",
    "\n",
    "# ohca_df['h3_l7'] = h3_l7\n",
    "\n",
    "# if min_lat < min(ohca_df['Latitude']): min_lat = min(ohca_df['Latitude'])\n",
    "# if max_lat > max(ohca_df['Latitude']): max_lat = max(ohca_df['Latitude'])\n",
    "# if min_lon < min(ohca_df['Longitude']): min_lon = min(ohca_df['Longitude'])\n",
    "# if max_lon > max(ohca_df['Longitude']): max_lon = max(ohca_df['Longitude'])\n",
    "\n",
    "# ohca_df = ohca_df.drop_duplicates(subset=['ReceivedTime', 'Latitude', 'Longitude'])\n",
    "# ohca_df['ReceivedTime'] = pd.to_datetime(ohca_df['ReceivedTime'])\n",
    "# ohca_df['ReceivedTime'] = ohca_df['ReceivedTime'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = np.concatenate((\n",
    "#             poi_df.amenity.unique(),\n",
    "#         ))\n",
    "# len(cols)\n",
    "\n",
    "# h3_l7_df = pd.DataFrame(data={'id': np.unique(np.concatenate((poi_df.h3_l7.unique(), ohca_df.h3_l7.unique())))})\n",
    "# h3_l7_df[cols] = 0\n",
    "\n",
    "# for i in range(poi_df.shape[0]):\n",
    "#     h3_l7_id = poi_df.iloc[i]['h3_l7']\n",
    "#     h3_l7_df.loc[h3_l7_df['id'] == h3_l7_id, poi_df.iloc[i]['amenity']] += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
