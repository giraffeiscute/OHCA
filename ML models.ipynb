{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h3\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_l7_df = pd.read_csv('h3_l7_df_new.csv')\n",
    "\n",
    "train_index=[]\n",
    "test_index=[]\n",
    "for i in range(0,h3_l7_df.shape[0]):\n",
    "    geo_location = h3.h3_to_geo(h3_l7_df.iloc[i]['id'])\n",
    "\n",
    "    if (geo_location[1]) > (-76.05): #把經度大於-76.05的 當train (東邊是train)\n",
    "        train_index.append(i)\n",
    "    else:\n",
    "        test_index.append(i)\n",
    "\n",
    "# 分割訓練集和測試集\n",
    "train_h3_l7_df = h3_l7_df.iloc[train_index]\n",
    "test_h3_l7_df = h3_l7_df.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 h3_l7_df 資料框中的 'id' 列移除，僅保留數據進行正規化\n",
    "h3_spatial_data = h3_l7_df.drop('id', axis=1)\n",
    "\n",
    "\n",
    "# # # 對數據進行正規化：將每個數據列的最小值調整為 0，最大值調整為 1\n",
    "normalized_spatial_data = (h3_spatial_data - h3_spatial_data.min()) / (h3_spatial_data.max() - h3_spatial_data.min())\n",
    "\n",
    "#設定OHCA正規化反函數 方便把預測結果返回原本scale\n",
    "ohca_reguli_inverse = (h3_l7_df.ohca.max()-h3_l7_df.ohca.min()) + h3_l7_df.ohca.min()\n",
    "\n",
    "# 將 DataFrame 轉換為 numpy array，並設定數據類型為 np.float64\n",
    "spatial_data = np.array(normalized_spatial_data).astype(np.float64)\n",
    "\n",
    "\n",
    "train_spatial_data = spatial_data[train_index]\n",
    "test_spatial_data = spatial_data[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离特征和标签\n",
    "X = spatial_data[:, :-1]  # 特征\n",
    "Y = spatial_data[:, -1]   # 标签（OHCA）\n",
    "\n",
    "X_train_reguli = train_spatial_data[:, :-1] \n",
    "y_train_reguli = train_spatial_data[:, -1] \n",
    "X_test_reguli = test_spatial_data[:, :-1] \n",
    "y_test_reguli = test_spatial_data[:, -1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.25128\n",
      "[1]\tvalidation_0-rmse:0.22448\n",
      "[2]\tvalidation_0-rmse:0.21175\n",
      "[3]\tvalidation_0-rmse:0.20171\n",
      "[4]\tvalidation_0-rmse:0.18749\n",
      "[5]\tvalidation_0-rmse:0.17932\n",
      "[6]\tvalidation_0-rmse:0.17204\n",
      "[7]\tvalidation_0-rmse:0.16052\n",
      "[8]\tvalidation_0-rmse:0.15528\n",
      "[9]\tvalidation_0-rmse:0.15295\n",
      "[10]\tvalidation_0-rmse:0.14736\n",
      "[11]\tvalidation_0-rmse:0.14550\n",
      "[12]\tvalidation_0-rmse:0.14403\n",
      "[13]\tvalidation_0-rmse:0.14363\n",
      "[14]\tvalidation_0-rmse:0.14072\n",
      "[15]\tvalidation_0-rmse:0.14103\n",
      "[16]\tvalidation_0-rmse:0.13846\n",
      "[17]\tvalidation_0-rmse:0.13953\n",
      "[18]\tvalidation_0-rmse:0.13796\n",
      "[19]\tvalidation_0-rmse:0.13793\n",
      "[20]\tvalidation_0-rmse:0.13958\n",
      "[21]\tvalidation_0-rmse:0.13895\n",
      "[22]\tvalidation_0-rmse:0.14029\n",
      "[23]\tvalidation_0-rmse:0.13908\n",
      "[24]\tvalidation_0-rmse:0.13733\n",
      "[25]\tvalidation_0-rmse:0.13911\n",
      "[26]\tvalidation_0-rmse:0.13841\n",
      "[27]\tvalidation_0-rmse:0.14016\n",
      "[28]\tvalidation_0-rmse:0.14010\n",
      "[29]\tvalidation_0-rmse:0.13993\n",
      "[30]\tvalidation_0-rmse:0.14074\n",
      "[31]\tvalidation_0-rmse:0.14083\n",
      "[32]\tvalidation_0-rmse:0.14140\n",
      "[33]\tvalidation_0-rmse:0.14097\n",
      "[34]\tvalidation_0-rmse:0.14064\n",
      "參數之選擇: {'subsample': 0.9, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.2, 'gamma': 0, 'colsample_bytree': 0.7}\n",
      "MAE of train set=  0.915199257210402\n",
      "R² of train set=  0.967830608732475\n",
      "MAE of test set=  6.450932422375425\n",
      "R² of test set=  0.676531086908509\n"
     ]
    }
   ],
   "source": [
    "# 定义XGBoost模型，提前设置early_stopping_rounds\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, early_stopping_rounds=10)\n",
    "\n",
    "# 定義 XGBoost 模型，並設置基本參數與早停條件\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',  # 設置目標函數為平方誤差\n",
    "    random_state=456546,               # 設定隨機種子以確保結果可重現 42 456546 276 320\n",
    "    early_stopping_rounds=10       # 如果驗證集指標在 10 輪內無改善則提前停止\n",
    ")\n",
    "\n",
    "# 定義超參數搜索的候選值範圍\n",
    "param_dist = {\n",
    "    'max_depth': [3, 6, 10, 12],          # 樹的最大深度，控制模型的複雜度\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2], # 每次迭代的步伐大小\n",
    "    'n_estimators': [50, 100, 200, 300],  # 樹的數量\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],    # 每棵樹隨機採樣的比例\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0], # 每棵樹使用的特徵比例\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],          # 控制節點分裂的最小增益\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],       # L1 正則化強度\n",
    "    'reg_lambda': [0, 0.01, 0.1, 1],      # L2 正則化強度\n",
    "    'min_child_weight': [1, 3, 5],        # 每個葉子節點的最小樣本權重\n",
    "}\n",
    "\n",
    "# 使用隨機搜尋進行超參數調整\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,                 # 基礎模型為 XGBoost\n",
    "    param_distributions=param_dist,      # 定義超參數搜索空間\n",
    "    n_iter=100,                          # 搜索 100 次\n",
    "    cv=5,                                # 使用 5 折交叉驗證\n",
    "    scoring='neg_mean_absolute_error',   # 評估指標為負的平均絕對誤差\n",
    "    n_jobs=-1,                           # 使用所有可用 CPU 加速計算\n",
    "    random_state=42                      # 設定隨機種子以確保結果可重現\n",
    ")\n",
    "\n",
    "# 訓練模型並進行超參數搜索\n",
    "random_search.fit(\n",
    "    X_train_reguli, y_train_reguli,                    # 訓練數據\n",
    "    eval_set=[(X_test_reguli, y_test_reguli)],         # 提供測試集進行早停監控\n",
    "    verbose=True                         # 在訓練過程中輸出詳細信息\n",
    ")\n",
    "\n",
    "# 提取經過超參數調整後的最佳模型 (判斷標準MAE)\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "# 顯示最佳超參數\n",
    "print(\"參數之選擇:\", random_search.best_params_)\n",
    "\n",
    "\n",
    "# # 預測訓練集結果\n",
    "# y_pred_train = best_xgb_model.predict(X_train)\n",
    "# # 預測測試集結果\n",
    "# y_pred_test = best_xgb_model.predict(X_test)\n",
    "\n",
    "# 預測訓練集結果\n",
    "y_head_train = best_xgb_model.predict(X_train_reguli)*ohca_reguli_inverse\n",
    "y_train = y_train_reguli*ohca_reguli_inverse\n",
    "# 預測測試集結果\n",
    "y_head_test = best_xgb_model.predict(X_test_reguli)*ohca_reguli_inverse\n",
    "y_test = y_test_reguli*ohca_reguli_inverse\n",
    "\n",
    "\n",
    "\n",
    "#評估成效\n",
    "train_mae = np.abs(y_head_train-y_train)\n",
    "train_ans_mae = train_mae.sum()/train_mae.shape[0]\n",
    "print('MAE of train set= ',train_ans_mae)\n",
    "# 計算殘差變異\n",
    "train_ss_residual = np.sum((y_train - y_head_train) ** 2)\n",
    "# 計算總變異量\n",
    "train_ss_total = np.sum((y_train - np.mean(y_train)) ** 2)\n",
    "# 計算 R²\n",
    "train_r_squared = 1 - (train_ss_residual / train_ss_total)\n",
    "print(\"R² of train set= \", train_r_squared)\n",
    "\n",
    "test_mae = np.abs(y_head_test-y_test)\n",
    "test_ans_mae = test_mae.sum()/test_mae.shape[0]\n",
    "print('MAE of test set= ',test_ans_mae)\n",
    "# 計算殘差變異\n",
    "test_ss_residual = np.sum((y_test - y_head_test) ** 2)\n",
    "# 計算總變異量\n",
    "test_ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "# 計算 R²\n",
    "test_r_squared = 1 - (test_ss_residual / test_ss_total)\n",
    "print(\"R² of test set= \", test_r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 找最佳seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# import xgboost as xgb\n",
    "\n",
    "# # 定義要嘗試的 random seed 列表\n",
    "# seed_list = range(300,400)\n",
    "\n",
    "# best_test_r2 = -np.inf  # 初始化最佳 R²\n",
    "# best_seed = None\n",
    "# best_model = None\n",
    "# best_params = None\n",
    "\n",
    "# for seed in seed_list:\n",
    "#     print(f\"\\n=== 正在嘗試 random seed: {seed} ===\")\n",
    "    \n",
    "#     # 定義 XGBoost 模型\n",
    "#     xgb_model = xgb.XGBRegressor(\n",
    "#         objective='reg:squarederror',\n",
    "#         random_state=seed,\n",
    "#         early_stopping_rounds=10,\n",
    "#         eval_metric='mae'\n",
    "#     )\n",
    "\n",
    "#     # 定義超參數搜索範圍\n",
    "#     param_dist = {\n",
    "#         'max_depth': [3, 6, 10, 12],\n",
    "#         'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "#         'n_estimators': [50, 100, 200, 300],\n",
    "#         'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "#         'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "#         'gamma': [0, 0.1, 0.2, 0.3],\n",
    "#         'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "#         'reg_lambda': [0, 0.01, 0.1, 1],\n",
    "#         'min_child_weight': [1, 3, 5],\n",
    "#     }\n",
    "\n",
    "#     # 使用隨機搜尋進行超參數調整\n",
    "#     random_search = RandomizedSearchCV(\n",
    "#         estimator=xgb_model,\n",
    "#         param_distributions=param_dist,\n",
    "#         n_iter=100,\n",
    "#         cv=5,\n",
    "#         scoring='neg_mean_absolute_error',\n",
    "#         n_jobs=-1,\n",
    "#         random_state=seed\n",
    "#     )\n",
    "\n",
    "#     # 訓練模型\n",
    "#     random_search.fit(\n",
    "#         X_train_reguli, y_train_reguli,\n",
    "#         eval_set=[(X_test_reguli, y_test_reguli)],\n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "#     # 獲取最佳模型\n",
    "#     current_model = random_search.best_estimator_\n",
    "    \n",
    "#     # 預測測試集\n",
    "#     y_head_test = current_model.predict(X_test_reguli) * ohca_reguli_inverse\n",
    "#     y_test = y_test_reguli * ohca_reguli_inverse\n",
    "    \n",
    "#     # 計算 R²\n",
    "#     ss_residual = np.sum((y_test - y_head_test) ** 2)\n",
    "#     ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "#     current_r2 = 1 - (ss_residual / ss_total)\n",
    "    \n",
    "#     print(f\"Test R²: {current_r2:.4f}\")\n",
    "    \n",
    "#     # 檢查是否為目前最佳模型\n",
    "#     if current_r2 > best_test_r2:\n",
    "#         best_test_r2 = current_r2\n",
    "#         best_seed = seed\n",
    "#         best_model = current_model\n",
    "#         best_params = random_search.best_params_\n",
    "#         print(f\"發現新的最佳 R²! Seed: {seed}, R²: {current_r2:.4f}\")\n",
    "\n",
    "# # 輸出最終結果\n",
    "# print(\"\\n=== 最佳結果 ===\")\n",
    "# print(f\"最佳 random seed: {best_seed}\")\n",
    "# print(f\"最佳 Test R²: {best_test_r2:.4f}\")\n",
    "# print(\"最佳參數組合:\")\n",
    "# for param, value in best_params.items():\n",
    "#     print(f\"{param}: {value}\")\n",
    "\n",
    "# # 使用最佳模型進行預測\n",
    "# y_head_train = best_model.predict(X_train_reguli) * ohca_reguli_inverse\n",
    "# y_train = y_train_reguli * ohca_reguli_inverse\n",
    "# y_head_test = best_model.predict(X_test_reguli) * ohca_reguli_inverse\n",
    "# y_test = y_test_reguli * ohca_reguli_inverse\n",
    "\n",
    "# # 評估成效\n",
    "# def evaluate_performance(y_true, y_pred, set_name):\n",
    "#     mae = np.mean(np.abs(y_pred - y_true))\n",
    "#     ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "#     ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "#     r2 = 1 - (ss_residual / ss_total)\n",
    "#     print(f\"\\n{set_name} 集評估:\")\n",
    "#     print(f\"MAE: {mae:.4f}\")\n",
    "#     print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# evaluate_performance(y_train, y_head_train, \"訓練\")\n",
    "# evaluate_performance(y_test, y_head_test, \"測試\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指定參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.26706\n",
      "[1]\tvalidation_0-rmse:0.26000\n",
      "[2]\tvalidation_0-rmse:0.25299\n",
      "[3]\tvalidation_0-rmse:0.24863\n",
      "[4]\tvalidation_0-rmse:0.24071\n",
      "[5]\tvalidation_0-rmse:0.23589\n",
      "[6]\tvalidation_0-rmse:0.22990\n",
      "[7]\tvalidation_0-rmse:0.22297\n",
      "[8]\tvalidation_0-rmse:0.21831\n",
      "[9]\tvalidation_0-rmse:0.21338\n",
      "[10]\tvalidation_0-rmse:0.20566\n",
      "[11]\tvalidation_0-rmse:0.20038\n",
      "[12]\tvalidation_0-rmse:0.19860\n",
      "[13]\tvalidation_0-rmse:0.19499\n",
      "[14]\tvalidation_0-rmse:0.19259\n",
      "[15]\tvalidation_0-rmse:0.18696\n",
      "[16]\tvalidation_0-rmse:0.18532\n",
      "[17]\tvalidation_0-rmse:0.18145\n",
      "[18]\tvalidation_0-rmse:0.17732\n",
      "[19]\tvalidation_0-rmse:0.17369\n",
      "[20]\tvalidation_0-rmse:0.16862\n",
      "[21]\tvalidation_0-rmse:0.16658\n",
      "[22]\tvalidation_0-rmse:0.16426\n",
      "[23]\tvalidation_0-rmse:0.16208\n",
      "[24]\tvalidation_0-rmse:0.16133\n",
      "[25]\tvalidation_0-rmse:0.15932\n",
      "[26]\tvalidation_0-rmse:0.15731\n",
      "[27]\tvalidation_0-rmse:0.15497\n",
      "[28]\tvalidation_0-rmse:0.15329\n",
      "[29]\tvalidation_0-rmse:0.15230\n",
      "[30]\tvalidation_0-rmse:0.15091\n",
      "[31]\tvalidation_0-rmse:0.14881\n",
      "[32]\tvalidation_0-rmse:0.14745\n",
      "[33]\tvalidation_0-rmse:0.14626\n",
      "[34]\tvalidation_0-rmse:0.14503\n",
      "[35]\tvalidation_0-rmse:0.14364\n",
      "[36]\tvalidation_0-rmse:0.14416\n",
      "[37]\tvalidation_0-rmse:0.14309\n",
      "[38]\tvalidation_0-rmse:0.14121\n",
      "[39]\tvalidation_0-rmse:0.13894\n",
      "[40]\tvalidation_0-rmse:0.13840\n",
      "[41]\tvalidation_0-rmse:0.13863\n",
      "[42]\tvalidation_0-rmse:0.13934\n",
      "[43]\tvalidation_0-rmse:0.13813\n",
      "[44]\tvalidation_0-rmse:0.13744\n",
      "[45]\tvalidation_0-rmse:0.13667\n",
      "[46]\tvalidation_0-rmse:0.13483\n",
      "[47]\tvalidation_0-rmse:0.13381\n",
      "[48]\tvalidation_0-rmse:0.13070\n",
      "[49]\tvalidation_0-rmse:0.13033\n",
      "[50]\tvalidation_0-rmse:0.12850\n",
      "[51]\tvalidation_0-rmse:0.12760\n",
      "[52]\tvalidation_0-rmse:0.12770\n",
      "[53]\tvalidation_0-rmse:0.12811\n",
      "[54]\tvalidation_0-rmse:0.12774\n",
      "[55]\tvalidation_0-rmse:0.12727\n",
      "[56]\tvalidation_0-rmse:0.12615\n",
      "[57]\tvalidation_0-rmse:0.12584\n",
      "[58]\tvalidation_0-rmse:0.12579\n",
      "[59]\tvalidation_0-rmse:0.12422\n",
      "[60]\tvalidation_0-rmse:0.12405\n",
      "[61]\tvalidation_0-rmse:0.12348\n",
      "[62]\tvalidation_0-rmse:0.12363\n",
      "[63]\tvalidation_0-rmse:0.12342\n",
      "[64]\tvalidation_0-rmse:0.12254\n",
      "[65]\tvalidation_0-rmse:0.12207\n",
      "[66]\tvalidation_0-rmse:0.12273\n",
      "[67]\tvalidation_0-rmse:0.12269\n",
      "[68]\tvalidation_0-rmse:0.12244\n",
      "[69]\tvalidation_0-rmse:0.12268\n",
      "[70]\tvalidation_0-rmse:0.12308\n",
      "[71]\tvalidation_0-rmse:0.12206\n",
      "[72]\tvalidation_0-rmse:0.12254\n",
      "[73]\tvalidation_0-rmse:0.12233\n",
      "[74]\tvalidation_0-rmse:0.12210\n",
      "[75]\tvalidation_0-rmse:0.12253\n",
      "[76]\tvalidation_0-rmse:0.12258\n",
      "[77]\tvalidation_0-rmse:0.12238\n",
      "[78]\tvalidation_0-rmse:0.12240\n",
      "[79]\tvalidation_0-rmse:0.12200\n",
      "[80]\tvalidation_0-rmse:0.12175\n",
      "[81]\tvalidation_0-rmse:0.12124\n",
      "[82]\tvalidation_0-rmse:0.12153\n",
      "[83]\tvalidation_0-rmse:0.12079\n",
      "[84]\tvalidation_0-rmse:0.12056\n",
      "[85]\tvalidation_0-rmse:0.12052\n",
      "[86]\tvalidation_0-rmse:0.12005\n",
      "[87]\tvalidation_0-rmse:0.12036\n",
      "[88]\tvalidation_0-rmse:0.12011\n",
      "[89]\tvalidation_0-rmse:0.12037\n",
      "[90]\tvalidation_0-rmse:0.12006\n",
      "[91]\tvalidation_0-rmse:0.12000\n",
      "[92]\tvalidation_0-rmse:0.11983\n",
      "[93]\tvalidation_0-rmse:0.11891\n",
      "[94]\tvalidation_0-rmse:0.11932\n",
      "[95]\tvalidation_0-rmse:0.11923\n",
      "[96]\tvalidation_0-rmse:0.11947\n",
      "[97]\tvalidation_0-rmse:0.12001\n",
      "[98]\tvalidation_0-rmse:0.11984\n",
      "[99]\tvalidation_0-rmse:0.11989\n",
      "MAE of train set=  1.6402824828962246\n",
      "R² of train set=  0.9323652560872638\n",
      "MAE of test set=  5.632138464045017\n",
      "R² of test set=  0.7574819584238226\n"
     ]
    }
   ],
   "source": [
    "# 定義XGBoost模型並指定參數\n",
    "best_xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=456546,\n",
    "    early_stopping_rounds=10,\n",
    "    # 以下是您指定的參數值，請根據需要修改這些值\n",
    "    max_depth=2,               # 樹的最大深度\n",
    "    learning_rate=0.05,         # 學習率\n",
    "    n_estimators=100,          # 樹的數量\n",
    "    subsample=0.6,            # 每棵樹隨機採樣的比例\n",
    "    colsample_bytree=0.6,      # 每棵樹使用的特徵比例\n",
    "    gamma=0,                # 控制節點分裂的最小增益\n",
    "    reg_alpha=0.05,            # L1正則化強度\n",
    "    reg_lambda=0.15,           # L2正則化強度\n",
    "    min_child_weight=3        # 每個葉子節點的最小樣本權重\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "best_xgb_model.fit(\n",
    "    X_train_reguli, y_train_reguli,\n",
    "    eval_set=[(X_test_reguli, y_test_reguli)],  # 提供測試集進行早停監控\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 預測訓練集結果\n",
    "y_head_train = best_xgb_model.predict(X_train_reguli) * ohca_reguli_inverse\n",
    "y_train = y_train_reguli * ohca_reguli_inverse\n",
    "# 預測測試集結果\n",
    "y_head_test = best_xgb_model.predict(X_test_reguli) * ohca_reguli_inverse\n",
    "y_test = y_test_reguli * ohca_reguli_inverse\n",
    "\n",
    "\n",
    "#評估成效\n",
    "train_mae = np.abs(y_head_train-y_train)\n",
    "train_ans_mae = train_mae.sum()/train_mae.shape[0]\n",
    "print('MAE of train set= ',train_ans_mae)\n",
    "# 計算殘差變異\n",
    "train_ss_residual = np.sum((y_train - y_head_train) ** 2)\n",
    "# 計算總變異量\n",
    "train_ss_total = np.sum((y_train - np.mean(y_train)) ** 2)\n",
    "# 計算 R²\n",
    "train_r_squared = 1 - (train_ss_residual / train_ss_total)\n",
    "print(\"R² of train set= \", train_r_squared)\n",
    "\n",
    "test_mae = np.abs(y_head_test-y_test)\n",
    "test_ans_mae = test_mae.sum()/test_mae.shape[0]\n",
    "print('MAE of test set= ',test_ans_mae)\n",
    "# 計算殘差變異\n",
    "test_ss_residual = np.sum((y_test - y_head_test) ** 2)\n",
    "# 計算總變異量\n",
    "test_ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "# 計算 R²\n",
    "test_r_squared = 1 - (test_ss_residual / test_ss_total)\n",
    "print(\"R² of test set= \", test_r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM(Different Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, r2_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # 正規化數據 (將特徵縮放到相同範圍，以提高模型的穩定性)\n",
    "# scaler = StandardScaler()\n",
    "# normalized_spatial_data = scaler.fit_transform(h3_spatial_data)\n",
    "\n",
    "# # 設定不同的核函數類型 (SVM 支援的四種主要核函數)\n",
    "# kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# # 用於存儲每個核函數的結果\n",
    "# results = {}\n",
    "\n",
    "# # 迴圈遍歷每種核函數\n",
    "# for kernel in kernels:\n",
    "#     print(f\"Training with {kernel} kernel...\")\n",
    "    \n",
    "#     # 設定 GridSearchCV 的超參數網格，測試不同的 C 和 epsilon 組合\n",
    "#     param_grid = {\n",
    "#         'C': [0.001, 0.01, 0.05, 0.1, 1],  # C 值較小時增加正則化效果\n",
    "#         'epsilon': [1e-5, 1e-4, 1e-3, 0.01, 0.05],  # epsilon 越小，模型對誤差的容忍度越低\n",
    "#         'kernel': [kernel],  # 使用當前核函數\n",
    "#     }\n",
    "\n",
    "#     # 初始化 SVR 模型\n",
    "#     svr = SVR()\n",
    "\n",
    "#     # 使用 GridSearchCV 進行超參數調整\n",
    "#     grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "#     # 訓練模型\n",
    "#     grid_search.fit(X_train_reguli, y_train_reguli)\n",
    "\n",
    "#     # 取得最佳模型\n",
    "#     best_svr_model = grid_search.best_estimator_\n",
    "\n",
    "#     # 進行預測並評估表現 (轉換回原始尺度)\n",
    "#     y_pred_train = best_svr_model.predict(X_train_reguli) * ohca_reguli_inverse\n",
    "#     y_pred_test = best_svr_model.predict(X_test_reguli) * ohca_reguli_inverse\n",
    "\n",
    "#     # 計算 MAE (平均絕對誤差) 和 R² (決定係數)\n",
    "#     mae_train = mean_absolute_error(y_train_reguli * ohca_reguli_inverse, y_pred_train)\n",
    "#     mae_test = mean_absolute_error(y_test_reguli * ohca_reguli_inverse, y_pred_test)\n",
    "\n",
    "#     r2_train = r2_score(y_train_reguli * ohca_reguli_inverse, y_pred_train)\n",
    "#     r2_test = r2_score(y_test_reguli * ohca_reguli_inverse, y_pred_test)\n",
    "\n",
    "#     # 存儲結果\n",
    "#     results[kernel] = {\n",
    "#         'Best Parameters': grid_search.best_params_,  # 最佳參數組合\n",
    "#         'Best Score': grid_search.best_score_,  # 最佳分數 (負 MAE)\n",
    "#         'MAE (Train)': mae_train,  # 訓練集 MAE\n",
    "#         'MAE (Test)': mae_test,  # 測試集 MAE\n",
    "#         'R² (Train)': r2_train,  # 訓練集 R²\n",
    "#         'R² (Test)': r2_test  # 測試集 R²\n",
    "#     }\n",
    "\n",
    "#     # 輸出結果\n",
    "#     print(f\"Best Parameters for {kernel}: {grid_search.best_params_}\")\n",
    "#     print(f\"Best Score for {kernel}: {grid_search.best_score_}\")\n",
    "#     print(f\"MAE (Train) for {kernel}: {mae_train}\")\n",
    "#     print(f\"MAE (Test) for {kernel}: {mae_test}\")\n",
    "#     print(f\"R² (Train) for {kernel}: {r2_train}\")\n",
    "#     print(f\"R² (Test) for {kernel}: {r2_test}\")\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "# # 輸出所有核函數的結果摘要\n",
    "# print(\"\\nSummary of Results:\")\n",
    "# for kernel, result in results.items():\n",
    "#     print(f\"Kernel: {kernel}\")\n",
    "#     for key, value in result.items():\n",
    "#         print(f\"{key}: {value}\")\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear\n",
      "C: 1\n",
      "Epsilon: 0.05\n",
      "MAE (Train): 2.1151099332685366\n",
      "MAE (Test): 5.870296489834363\n",
      "R² (Train): 0.9573184939226599\n",
      "R² (Test): 0.7326980718539038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 正規化數據 (將特徵縮放到相同範圍，以提高模型的穩定性)\n",
    "scaler = StandardScaler()\n",
    "normalized_spatial_data = scaler.fit_transform(h3_spatial_data)\n",
    "\n",
    "# 設定 SVR 參數\n",
    "kernel = 'linear'  # 指定核函數\n",
    "C = 1  # 指定 C 參數\n",
    "epsilon = 0.05  # 指定 epsilon 參數\n",
    "\n",
    "# 初始化 SVR 模型\n",
    "svr = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "\n",
    "# 訓練模型\n",
    "svr.fit(X_train_reguli, y_train_reguli)\n",
    "\n",
    "# 進行預測並評估表現 (轉換回原始尺度)\n",
    "y_pred_train = svr.predict(X_train_reguli) * ohca_reguli_inverse\n",
    "y_pred_test = svr.predict(X_test_reguli) * ohca_reguli_inverse\n",
    "\n",
    "\n",
    "# 計算 MAE (平均絕對誤差) 和 R² (決定係數)\n",
    "mae_train = mean_absolute_error(y_train_reguli * ohca_reguli_inverse, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test_reguli * ohca_reguli_inverse, y_pred_test)\n",
    "\n",
    "r2_train = r2_score(y_train_reguli * ohca_reguli_inverse, y_pred_train)\n",
    "r2_test = r2_score(y_test_reguli * ohca_reguli_inverse, y_pred_test)\n",
    "\n",
    "\n",
    "# 輸出結果\n",
    "print(f\"Kernel: {kernel}\")\n",
    "print(f\"C: {C}\")\n",
    "print(f\"Epsilon: {epsilon}\")\n",
    "print(f\"MAE (Train): {mae_train}\")\n",
    "print(f\"MAE (Test): {mae_test}\")\n",
    "print(f\"R² (Train): {r2_train}\")\n",
    "print(f\"R² (Test): {r2_test}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
